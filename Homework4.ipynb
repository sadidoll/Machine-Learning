{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5kWYanoTTk5EIX1bkn5ju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sadidoll/Machine-Learning/blob/main/Homework4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSaeY7X1u5nl"
      },
      "source": [
        "import math\r\n",
        "import random\r\n",
        "import time\r\n",
        "import numpy as np\r\n",
        "from scipy.spatial import distance\r\n",
        "from tkinter import *\r\n",
        "\r\n",
        "######################################################################\r\n",
        "# This section contains functions for loading CSV (comma separated values)\r\n",
        "# files and convert them to a dataset of instances.\r\n",
        "# Each instance is a tuple of attributes. The entire dataset is a list\r\n",
        "# of tuples.\r\n",
        "######################################################################\r\n",
        "\r\n",
        "# Loads a CSV files into a list of tuples.\r\n",
        "# Ignores the first row of the file (header).\r\n",
        "# Numeric attributes are converted to floats, nominal attributes\r\n",
        "# are represented with strings.\r\n",
        "# Parameters:\r\n",
        "#   fileName: name of the CSV file to be read\r\n",
        "# Returns: a list of tuples\r\n",
        "def loadCSV(fileName):\r\n",
        "    fileHandler = open(fileName, \"rt\")\r\n",
        "    lines = fileHandler.readlines()\r\n",
        "    fileHandler.close()\r\n",
        "    del lines[0] # remove the header\r\n",
        "    dataset = []\r\n",
        "    for line in lines:\r\n",
        "        instance = lineToTuple(line)\r\n",
        "        dataset.append(instance)\r\n",
        "    return dataset\r\n",
        "\r\n",
        "# Converts a comma separated string into a tuple\r\n",
        "# Parameters\r\n",
        "#   line: a string\r\n",
        "# Returns: a tuple\r\n",
        "def lineToTuple(line):\r\n",
        "    # remove leading/trailing witespace and newlines\r\n",
        "    cleanLine = line.strip()\r\n",
        "    # get rid of quotes\r\n",
        "    cleanLine = cleanLine.replace('\"', '')\r\n",
        "    # separate the fields\r\n",
        "    lineList = cleanLine.split(\",\")\r\n",
        "    # convert strings into numbers\r\n",
        "    stringsToNumbers(lineList)\r\n",
        "    lineTuple = tuple(lineList)\r\n",
        "    return lineTuple\r\n",
        "\r\n",
        "# Destructively converts all the string elements representing numbers\r\n",
        "# to floating point numbers.\r\n",
        "# Parameters:\r\n",
        "#   myList: a list of strings\r\n",
        "# Returns None\r\n",
        "def stringsToNumbers(myList):\r\n",
        "    for i in range(len(myList)):\r\n",
        "        if (isValidNumberString(myList[i])):\r\n",
        "            myList[i] = float(myList[i])\r\n",
        "\r\n",
        "# Checks if a given string can be safely converted into a positive float.\r\n",
        "# Parameters:\r\n",
        "#   s: the string to be checked\r\n",
        "# Returns: True if the string represents a positive float, False otherwise\r\n",
        "def isValidNumberString(s):\r\n",
        "  if len(s) == 0:\r\n",
        "    return False\r\n",
        "  if  len(s) > 1 and s[0] == \"-\":\r\n",
        "      s = s[1:]\r\n",
        "  for c in s:\r\n",
        "    if c not in \"0123456789.\":\r\n",
        "      return False\r\n",
        "  return True\r\n",
        "\r\n",
        "######################################################################\r\n",
        "# This section contains functions for clustering a dataset\r\n",
        "# using the k-means algorithm.\r\n",
        "######################################################################\r\n",
        "\r\n",
        "def distance(instance1, instance2, distance_type = 'Euclidean'):\r\n",
        "  if distance_type == 'Euclidean':\r\n",
        "    if instance1 == None or instance2 == None:\r\n",
        "        return float(\"inf\")\r\n",
        "    sumOfSquares = 0\r\n",
        "    for i in range(1, len(instance1)):\r\n",
        "        sumOfSquares += (instance1[i] - instance2[i])**2\r\n",
        "    return sumOfSquares\r\n",
        "  if distance_type == 'Manhattan':\r\n",
        "    #print('In manhattan loop')\r\n",
        "    if instance1 == None or instance2 == None:\r\n",
        "        return float(\"inf\")\r\n",
        "    return abs(instance1[1] - instance2[1]) + abs(instance1[2] - instance2[2])\r\n",
        "  if distance_type == 'Cosine':\r\n",
        "    if instance1 == None or instance2 == None:\r\n",
        "        return float(\"inf\")\r\n",
        "    point1 = instance1[-2:]\r\n",
        "    point2 = instance2[-2:] \r\n",
        "    return (dot(point1,point2)/cross(point1,point2)) \r\n",
        "  if distance_type == 'Jaccard':\r\n",
        "    if instance1 == None or instance2 == None:\r\n",
        "        return float(\"inf\")\r\n",
        "    distance_j = distance.jaccard (instance1,instance2)\r\n",
        "    return distance_j \r\n",
        "  if distance_type == None:\r\n",
        "    return float(\"inf\") \r\n",
        "\r\n",
        "def meanInstance(name, instanceList):\r\n",
        "    numInstances = len(instanceList)\r\n",
        "    if (numInstances == 0):\r\n",
        "        return\r\n",
        "    numAttributes = len(instanceList[0])\r\n",
        "    means = [name] + [0] * (numAttributes-1)\r\n",
        "    for instance in instanceList:\r\n",
        "        for i in range(1, numAttributes):\r\n",
        "            means[i] += instance[i]\r\n",
        "    for i in range(1, numAttributes):\r\n",
        "        means[i] /= float(numInstances)\r\n",
        "    return tuple(means)\r\n",
        "\r\n",
        "def assign(instance, centroids, distance_type = 'Euclidean' ):\r\n",
        "    minDistance = distance(instance, centroids[0],distance_type)\r\n",
        "    minDistanceIndex = 0\r\n",
        "    for i in range(1, len(centroids)):\r\n",
        "        d = distance(instance, centroids[i], distance_type)\r\n",
        "        if (d < minDistance):\r\n",
        "            minDistance = d\r\n",
        "            minDistanceIndex = i\r\n",
        "    return minDistanceIndex\r\n",
        "\r\n",
        "def createEmptyListOfLists(numSubLists):\r\n",
        "    myList = []\r\n",
        "    for i in range(numSubLists):\r\n",
        "        myList.append([])\r\n",
        "    return myList\r\n",
        "\r\n",
        "def assignAll(instances, centroids, distance_type = 'Euclidean'):\r\n",
        "    clusters = createEmptyListOfLists(len(centroids))\r\n",
        "    for instance in instances:\r\n",
        "        clusterIndex = assign(instance, centroids, distance_type)\r\n",
        "        clusters[clusterIndex].append(instance)\r\n",
        "    return clusters\r\n",
        "\r\n",
        "def computeCentroids(clusters):\r\n",
        "    centroids = []\r\n",
        "    for i in range(len(clusters)):\r\n",
        "        name = \"centroid\" + str(i)\r\n",
        "        centroid = meanInstance(name, clusters[i])\r\n",
        "        centroids.append(centroid)\r\n",
        "    return centroids\r\n",
        "\r\n",
        "def kmeans(instances, k, initCentroids=None, distance_type = 'Euclidean'):\r\n",
        "    result = {}\r\n",
        "    if (initCentroids == None or len(initCentroids) < k):\r\n",
        "        # randomly select k initial centroids\r\n",
        "        random.seed(time.time())\r\n",
        "        centroids = random.sample(instances, k)\r\n",
        "    else:\r\n",
        "        centroids = initCentroids\r\n",
        "    prevCentroids = []\r\n",
        "#    if animation:\r\n",
        "#        delay = 1.0 # seconds\r\n",
        "#        canvas = prepareWindow(instances)\r\n",
        " #       clusters = createEmptyListOfLists(k)\r\n",
        "  #      clusters[0] = instances\r\n",
        " #       paintClusters2D(canvas, clusters, centroids, \"Initial centroids\")\r\n",
        " #       time.sleep(delay)\r\n",
        "    iteration = 0\r\n",
        "    while (centroids != prevCentroids):\r\n",
        "        iteration += 1\r\n",
        "        clusters = assignAll(instances, centroids, distance_type)\r\n",
        " #       if animation:\r\n",
        "  #          paintClusters2D(canvas, clusters, centroids, \"Assign %d\" % iteration)\r\n",
        "  #          time.sleep(delay)\r\n",
        "        prevCentroids = centroids\r\n",
        "        centroids = computeCentroids(clusters)\r\n",
        "        withinss = computeWithinss(clusters, centroids, distance_type)\r\n",
        "#        if animation:\r\n",
        "  #          paintClusters2D(canvas, clusters, centroids,\r\n",
        "  #                          \"Update %d, withinss %.1f\" % (iteration, withinss))\r\n",
        "   #         time.sleep(delay)\r\n",
        "    result[\"clusters\"] = clusters\r\n",
        "    result[\"centroids\"] = centroids\r\n",
        "    result[\"withinss\"] = withinss\r\n",
        "    return result\r\n",
        "\r\n",
        "def computeWithinss(clusters, centroids, distance_type = 'Euclidean'):\r\n",
        "    result = 0\r\n",
        "    for i in range(len(centroids)):\r\n",
        "        centroid = centroids[i]\r\n",
        "        cluster = clusters[i]\r\n",
        "        for instance in cluster:\r\n",
        "            result += distance(centroid, instance, distance_type)\r\n",
        "    return result\r\n",
        "\r\n",
        "# Repeats k-means clustering n times, and returns the clustering\r\n",
        "# with the smallest withinss\r\n",
        "def repeatedKMeans(instances, k, n, initCentroids=None,distance_type = 'Euclidean'):\r\n",
        "    bestClustering = {}\r\n",
        "    bestClustering[\"withinss\"] = float(\"inf\")\r\n",
        "    for i in range(1, n+1):\r\n",
        "        print (\"k-means trial %d,\" % i ),\r\n",
        "        trialClustering = kmeans(instances, k, initCentroids,distance_type)\r\n",
        "        print (\"withinss: %.1f\" % trialClustering[\"withinss\"])\r\n",
        "        if trialClustering[\"withinss\"] < bestClustering[\"withinss\"]:\r\n",
        "            bestClustering = trialClustering\r\n",
        "            minWithinssTrial = i\r\n",
        "    print (\"Trial with minimum withinss:\", minWithinssTrial)\r\n",
        "    return bestClustering\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "R9eAasy8O0Df",
        "outputId": "870642bb-b653-4872-c76c-4a58d909ae32"
      },
      "source": [
        "from google.colab import files\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-51d1f3c8-380a-4b9b-9f20-d5116d4749bd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-51d1f3c8-380a-4b9b-9f20-d5116d4749bd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Team.csv to Team (5).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KjeaKmAnsif"
      },
      "source": [
        "dataset = loadCSV(\"Team.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEU3oHhXkmG7"
      },
      "source": [
        "##Task 1 : (1) Initializing two centroids, (4, 6) and (5, 4) using Manhattan distance as the distance metric along with performing one iteration of the K-means algorithm and the reporting the coordinates of the resulting centroids.Also, Using K-Means to find two clusters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kSNaQ-DngEJ",
        "outputId": "681efcc6-7894-4789-deb3-facfe76f5151"
      },
      "source": [
        "\r\n",
        "centroids = [('centroidA',4,6),('centroidB',5,4)]\r\n",
        "cluster_1 = kmeans(dataset, 2, initCentroids = centroids, distance_type = 'Manhattan')\r\n",
        "\r\n",
        "#print(\"The two clusters using k-means to find clusters: \")\r\n",
        "cluster_2 = repeatedKMeans(dataset, 2, 100,centroids, distance_type = 'Manhattan')\r\n",
        "printTable(cluster_1['centroids'])\r\n",
        "cluster_1[\"clusters\"]\r\n",
        "cluster_2[\"clusters\"]\r\n",
        "#clusters_1[\"clusters\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k-means trial 1,\n",
            "withinss: 27.0\n",
            "k-means trial 2,\n",
            "withinss: 27.0\n",
            "k-means trial 3,\n",
            "withinss: 27.0\n",
            "k-means trial 4,\n",
            "withinss: 27.0\n",
            "k-means trial 5,\n",
            "withinss: 27.0\n",
            "k-means trial 6,\n",
            "withinss: 27.0\n",
            "k-means trial 7,\n",
            "withinss: 27.0\n",
            "k-means trial 8,\n",
            "withinss: 27.0\n",
            "k-means trial 9,\n",
            "withinss: 27.0\n",
            "k-means trial 10,\n",
            "withinss: 27.0\n",
            "k-means trial 11,\n",
            "withinss: 27.0\n",
            "k-means trial 12,\n",
            "withinss: 27.0\n",
            "k-means trial 13,\n",
            "withinss: 27.0\n",
            "k-means trial 14,\n",
            "withinss: 27.0\n",
            "k-means trial 15,\n",
            "withinss: 27.0\n",
            "k-means trial 16,\n",
            "withinss: 27.0\n",
            "k-means trial 17,\n",
            "withinss: 27.0\n",
            "k-means trial 18,\n",
            "withinss: 27.0\n",
            "k-means trial 19,\n",
            "withinss: 27.0\n",
            "k-means trial 20,\n",
            "withinss: 27.0\n",
            "k-means trial 21,\n",
            "withinss: 27.0\n",
            "k-means trial 22,\n",
            "withinss: 27.0\n",
            "k-means trial 23,\n",
            "withinss: 27.0\n",
            "k-means trial 24,\n",
            "withinss: 27.0\n",
            "k-means trial 25,\n",
            "withinss: 27.0\n",
            "k-means trial 26,\n",
            "withinss: 27.0\n",
            "k-means trial 27,\n",
            "withinss: 27.0\n",
            "k-means trial 28,\n",
            "withinss: 27.0\n",
            "k-means trial 29,\n",
            "withinss: 27.0\n",
            "k-means trial 30,\n",
            "withinss: 27.0\n",
            "k-means trial 31,\n",
            "withinss: 27.0\n",
            "k-means trial 32,\n",
            "withinss: 27.0\n",
            "k-means trial 33,\n",
            "withinss: 27.0\n",
            "k-means trial 34,\n",
            "withinss: 27.0\n",
            "k-means trial 35,\n",
            "withinss: 27.0\n",
            "k-means trial 36,\n",
            "withinss: 27.0\n",
            "k-means trial 37,\n",
            "withinss: 27.0\n",
            "k-means trial 38,\n",
            "withinss: 27.0\n",
            "k-means trial 39,\n",
            "withinss: 27.0\n",
            "k-means trial 40,\n",
            "withinss: 27.0\n",
            "k-means trial 41,\n",
            "withinss: 27.0\n",
            "k-means trial 42,\n",
            "withinss: 27.0\n",
            "k-means trial 43,\n",
            "withinss: 27.0\n",
            "k-means trial 44,\n",
            "withinss: 27.0\n",
            "k-means trial 45,\n",
            "withinss: 27.0\n",
            "k-means trial 46,\n",
            "withinss: 27.0\n",
            "k-means trial 47,\n",
            "withinss: 27.0\n",
            "k-means trial 48,\n",
            "withinss: 27.0\n",
            "k-means trial 49,\n",
            "withinss: 27.0\n",
            "k-means trial 50,\n",
            "withinss: 27.0\n",
            "k-means trial 51,\n",
            "withinss: 27.0\n",
            "k-means trial 52,\n",
            "withinss: 27.0\n",
            "k-means trial 53,\n",
            "withinss: 27.0\n",
            "k-means trial 54,\n",
            "withinss: 27.0\n",
            "k-means trial 55,\n",
            "withinss: 27.0\n",
            "k-means trial 56,\n",
            "withinss: 27.0\n",
            "k-means trial 57,\n",
            "withinss: 27.0\n",
            "k-means trial 58,\n",
            "withinss: 27.0\n",
            "k-means trial 59,\n",
            "withinss: 27.0\n",
            "k-means trial 60,\n",
            "withinss: 27.0\n",
            "k-means trial 61,\n",
            "withinss: 27.0\n",
            "k-means trial 62,\n",
            "withinss: 27.0\n",
            "k-means trial 63,\n",
            "withinss: 27.0\n",
            "k-means trial 64,\n",
            "withinss: 27.0\n",
            "k-means trial 65,\n",
            "withinss: 27.0\n",
            "k-means trial 66,\n",
            "withinss: 27.0\n",
            "k-means trial 67,\n",
            "withinss: 27.0\n",
            "k-means trial 68,\n",
            "withinss: 27.0\n",
            "k-means trial 69,\n",
            "withinss: 27.0\n",
            "k-means trial 70,\n",
            "withinss: 27.0\n",
            "k-means trial 71,\n",
            "withinss: 27.0\n",
            "k-means trial 72,\n",
            "withinss: 27.0\n",
            "k-means trial 73,\n",
            "withinss: 27.0\n",
            "k-means trial 74,\n",
            "withinss: 27.0\n",
            "k-means trial 75,\n",
            "withinss: 27.0\n",
            "k-means trial 76,\n",
            "withinss: 27.0\n",
            "k-means trial 77,\n",
            "withinss: 27.0\n",
            "k-means trial 78,\n",
            "withinss: 27.0\n",
            "k-means trial 79,\n",
            "withinss: 27.0\n",
            "k-means trial 80,\n",
            "withinss: 27.0\n",
            "k-means trial 81,\n",
            "withinss: 27.0\n",
            "k-means trial 82,\n",
            "withinss: 27.0\n",
            "k-means trial 83,\n",
            "withinss: 27.0\n",
            "k-means trial 84,\n",
            "withinss: 27.0\n",
            "k-means trial 85,\n",
            "withinss: 27.0\n",
            "k-means trial 86,\n",
            "withinss: 27.0\n",
            "k-means trial 87,\n",
            "withinss: 27.0\n",
            "k-means trial 88,\n",
            "withinss: 27.0\n",
            "k-means trial 89,\n",
            "withinss: 27.0\n",
            "k-means trial 90,\n",
            "withinss: 27.0\n",
            "k-means trial 91,\n",
            "withinss: 27.0\n",
            "k-means trial 92,\n",
            "withinss: 27.0\n",
            "k-means trial 93,\n",
            "withinss: 27.0\n",
            "k-means trial 94,\n",
            "withinss: 27.0\n",
            "k-means trial 95,\n",
            "withinss: 27.0\n",
            "k-means trial 96,\n",
            "withinss: 27.0\n",
            "k-means trial 97,\n",
            "withinss: 27.0\n",
            "k-means trial 98,\n",
            "withinss: 27.0\n",
            "k-means trial 99,\n",
            "withinss: 27.0\n",
            "k-means trial 100,\n",
            "withinss: 27.0\n",
            "Trial with minimum withinss: 1\n",
            "centroid0\t4.00 6.33 \n",
            "centroid1\t5.57 3.57 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('X1', 3.0, 5.0), ('X3', 2.0, 8.0), ('X10', 7.0, 6.0)],\n",
              " [('X2', 3.0, 4.0),\n",
              "  ('X4', 2.0, 3.0),\n",
              "  ('X5', 6.0, 2.0),\n",
              "  ('X6', 6.0, 4.0),\n",
              "  ('X7', 7.0, 3.0),\n",
              "  ('X8', 7.0, 4.0),\n",
              "  ('X9', 8.0, 5.0)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1bZKuQYnxWM"
      },
      "source": [
        "##(2) Initializing two centroids, (4, 6) and (5, 4) using Euclidean distance as the distance metric along with performing one iteration of the K-means algorithm and the reporting the coordinates of the resulting centroids.Also, Using K-Means to find two clusters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdth7J8CqCJo",
        "outputId": "55b8091f-661a-48aa-d1e2-9f667e84f397"
      },
      "source": [
        "\r\n",
        "centroids_2 = [('centroidA',4,6),('centroidB',5,4)]\r\n",
        "cluster_12 = kmeans(dataset, 2, initCentroids = centroids_2, distance_type = 'Euclidean')\r\n",
        "\r\n",
        "#print(\"The two clusters using k-means to find clusters: \")\r\n",
        "cluster_22 = repeatedKMeans(dataset, 2, 100,centroids_2, distance_type = 'Euclidean')\r\n",
        "printTable(cluster_12['centroids'])\r\n",
        "cluster_12[\"clusters\"]\r\n",
        "cluster_22[\"clusters\"]\r\n",
        "#clusters_1[\"clusters\"]\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k-means trial 1,\n",
            "withinss: 27.8\n",
            "k-means trial 2,\n",
            "withinss: 27.8\n",
            "k-means trial 3,\n",
            "withinss: 27.8\n",
            "k-means trial 4,\n",
            "withinss: 27.8\n",
            "k-means trial 5,\n",
            "withinss: 27.8\n",
            "k-means trial 6,\n",
            "withinss: 27.8\n",
            "k-means trial 7,\n",
            "withinss: 27.8\n",
            "k-means trial 8,\n",
            "withinss: 27.8\n",
            "k-means trial 9,\n",
            "withinss: 27.8\n",
            "k-means trial 10,\n",
            "withinss: 27.8\n",
            "k-means trial 11,\n",
            "withinss: 27.8\n",
            "k-means trial 12,\n",
            "withinss: 27.8\n",
            "k-means trial 13,\n",
            "withinss: 27.8\n",
            "k-means trial 14,\n",
            "withinss: 27.8\n",
            "k-means trial 15,\n",
            "withinss: 27.8\n",
            "k-means trial 16,\n",
            "withinss: 27.8\n",
            "k-means trial 17,\n",
            "withinss: 27.8\n",
            "k-means trial 18,\n",
            "withinss: 27.8\n",
            "k-means trial 19,\n",
            "withinss: 27.8\n",
            "k-means trial 20,\n",
            "withinss: 27.8\n",
            "k-means trial 21,\n",
            "withinss: 27.8\n",
            "k-means trial 22,\n",
            "withinss: 27.8\n",
            "k-means trial 23,\n",
            "withinss: 27.8\n",
            "k-means trial 24,\n",
            "withinss: 27.8\n",
            "k-means trial 25,\n",
            "withinss: 27.8\n",
            "k-means trial 26,\n",
            "withinss: 27.8\n",
            "k-means trial 27,\n",
            "withinss: 27.8\n",
            "k-means trial 28,\n",
            "withinss: 27.8\n",
            "k-means trial 29,\n",
            "withinss: 27.8\n",
            "k-means trial 30,\n",
            "withinss: 27.8\n",
            "k-means trial 31,\n",
            "withinss: 27.8\n",
            "k-means trial 32,\n",
            "withinss: 27.8\n",
            "k-means trial 33,\n",
            "withinss: 27.8\n",
            "k-means trial 34,\n",
            "withinss: 27.8\n",
            "k-means trial 35,\n",
            "withinss: 27.8\n",
            "k-means trial 36,\n",
            "withinss: 27.8\n",
            "k-means trial 37,\n",
            "withinss: 27.8\n",
            "k-means trial 38,\n",
            "withinss: 27.8\n",
            "k-means trial 39,\n",
            "withinss: 27.8\n",
            "k-means trial 40,\n",
            "withinss: 27.8\n",
            "k-means trial 41,\n",
            "withinss: 27.8\n",
            "k-means trial 42,\n",
            "withinss: 27.8\n",
            "k-means trial 43,\n",
            "withinss: 27.8\n",
            "k-means trial 44,\n",
            "withinss: 27.8\n",
            "k-means trial 45,\n",
            "withinss: 27.8\n",
            "k-means trial 46,\n",
            "withinss: 27.8\n",
            "k-means trial 47,\n",
            "withinss: 27.8\n",
            "k-means trial 48,\n",
            "withinss: 27.8\n",
            "k-means trial 49,\n",
            "withinss: 27.8\n",
            "k-means trial 50,\n",
            "withinss: 27.8\n",
            "k-means trial 51,\n",
            "withinss: 27.8\n",
            "k-means trial 52,\n",
            "withinss: 27.8\n",
            "k-means trial 53,\n",
            "withinss: 27.8\n",
            "k-means trial 54,\n",
            "withinss: 27.8\n",
            "k-means trial 55,\n",
            "withinss: 27.8\n",
            "k-means trial 56,\n",
            "withinss: 27.8\n",
            "k-means trial 57,\n",
            "withinss: 27.8\n",
            "k-means trial 58,\n",
            "withinss: 27.8\n",
            "k-means trial 59,\n",
            "withinss: 27.8\n",
            "k-means trial 60,\n",
            "withinss: 27.8\n",
            "k-means trial 61,\n",
            "withinss: 27.8\n",
            "k-means trial 62,\n",
            "withinss: 27.8\n",
            "k-means trial 63,\n",
            "withinss: 27.8\n",
            "k-means trial 64,\n",
            "withinss: 27.8\n",
            "k-means trial 65,\n",
            "withinss: 27.8\n",
            "k-means trial 66,\n",
            "withinss: 27.8\n",
            "k-means trial 67,\n",
            "withinss: 27.8\n",
            "k-means trial 68,\n",
            "withinss: 27.8\n",
            "k-means trial 69,\n",
            "withinss: 27.8\n",
            "k-means trial 70,\n",
            "withinss: 27.8\n",
            "k-means trial 71,\n",
            "withinss: 27.8\n",
            "k-means trial 72,\n",
            "withinss: 27.8\n",
            "k-means trial 73,\n",
            "withinss: 27.8\n",
            "k-means trial 74,\n",
            "withinss: 27.8\n",
            "k-means trial 75,\n",
            "withinss: 27.8\n",
            "k-means trial 76,\n",
            "withinss: 27.8\n",
            "k-means trial 77,\n",
            "withinss: 27.8\n",
            "k-means trial 78,\n",
            "withinss: 27.8\n",
            "k-means trial 79,\n",
            "withinss: 27.8\n",
            "k-means trial 80,\n",
            "withinss: 27.8\n",
            "k-means trial 81,\n",
            "withinss: 27.8\n",
            "k-means trial 82,\n",
            "withinss: 27.8\n",
            "k-means trial 83,\n",
            "withinss: 27.8\n",
            "k-means trial 84,\n",
            "withinss: 27.8\n",
            "k-means trial 85,\n",
            "withinss: 27.8\n",
            "k-means trial 86,\n",
            "withinss: 27.8\n",
            "k-means trial 87,\n",
            "withinss: 27.8\n",
            "k-means trial 88,\n",
            "withinss: 27.8\n",
            "k-means trial 89,\n",
            "withinss: 27.8\n",
            "k-means trial 90,\n",
            "withinss: 27.8\n",
            "k-means trial 91,\n",
            "withinss: 27.8\n",
            "k-means trial 92,\n",
            "withinss: 27.8\n",
            "k-means trial 93,\n",
            "withinss: 27.8\n",
            "k-means trial 94,\n",
            "withinss: 27.8\n",
            "k-means trial 95,\n",
            "withinss: 27.8\n",
            "k-means trial 96,\n",
            "withinss: 27.8\n",
            "k-means trial 97,\n",
            "withinss: 27.8\n",
            "k-means trial 98,\n",
            "withinss: 27.8\n",
            "k-means trial 99,\n",
            "withinss: 27.8\n",
            "k-means trial 100,\n",
            "withinss: 27.8\n",
            "Trial with minimum withinss: 1\n",
            "centroid0\t2.50 5.00 \n",
            "centroid1\t6.83 4.00 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('X1', 3.0, 5.0), ('X2', 3.0, 4.0), ('X3', 2.0, 8.0), ('X4', 2.0, 3.0)],\n",
              " [('X5', 6.0, 2.0),\n",
              "  ('X6', 6.0, 4.0),\n",
              "  ('X7', 7.0, 3.0),\n",
              "  ('X8', 7.0, 4.0),\n",
              "  ('X9', 8.0, 5.0),\n",
              "  ('X10', 7.0, 6.0)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPmcJkVE50SM"
      },
      "source": [
        "##(3) Initializing two centroids, (3, 3) and (8, 3) using Manhattan distance as the distance metric along with performing one iteration of the K-means algorithm and the reporting the coordinates of the resulting centroids.Also, Using K-Means to find two clusters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVebmm1M58Mh",
        "outputId": "9416303d-6e1f-44af-ebcb-60af03d55bc9"
      },
      "source": [
        "\r\n",
        "centroids_3 = [('centroidA',3,3),('centroidB',8,3)]\r\n",
        "cluster_13 = kmeans(dataset, 2, initCentroids = centroids_3, distance_type = 'Manhattan')\r\n",
        "\r\n",
        "#print(\"The two clusters using k-means to find clusters: \")\r\n",
        "cluster_23 = repeatedKMeans(dataset, 2, 100,centroids_3,distance_type = 'Manhattan')\r\n",
        "printTable(cluster_13['centroids'])\r\n",
        "cluster_13[\"clusters\"]\r\n",
        "cluster_23[\"clusters\"]\r\n",
        "#clusters_1[\"clusters\"]\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k-means trial 1,\n",
            "withinss: 17.3\n",
            "k-means trial 2,\n",
            "withinss: 17.3\n",
            "k-means trial 3,\n",
            "withinss: 17.3\n",
            "k-means trial 4,\n",
            "withinss: 17.3\n",
            "k-means trial 5,\n",
            "withinss: 17.3\n",
            "k-means trial 6,\n",
            "withinss: 17.3\n",
            "k-means trial 7,\n",
            "withinss: 17.3\n",
            "k-means trial 8,\n",
            "withinss: 17.3\n",
            "k-means trial 9,\n",
            "withinss: 17.3\n",
            "k-means trial 10,\n",
            "withinss: 17.3\n",
            "k-means trial 11,\n",
            "withinss: 17.3\n",
            "k-means trial 12,\n",
            "withinss: 17.3\n",
            "k-means trial 13,\n",
            "withinss: 17.3\n",
            "k-means trial 14,\n",
            "withinss: 17.3\n",
            "k-means trial 15,\n",
            "withinss: 17.3\n",
            "k-means trial 16,\n",
            "withinss: 17.3\n",
            "k-means trial 17,\n",
            "withinss: 17.3\n",
            "k-means trial 18,\n",
            "withinss: 17.3\n",
            "k-means trial 19,\n",
            "withinss: 17.3\n",
            "k-means trial 20,\n",
            "withinss: 17.3\n",
            "k-means trial 21,\n",
            "withinss: 17.3\n",
            "k-means trial 22,\n",
            "withinss: 17.3\n",
            "k-means trial 23,\n",
            "withinss: 17.3\n",
            "k-means trial 24,\n",
            "withinss: 17.3\n",
            "k-means trial 25,\n",
            "withinss: 17.3\n",
            "k-means trial 26,\n",
            "withinss: 17.3\n",
            "k-means trial 27,\n",
            "withinss: 17.3\n",
            "k-means trial 28,\n",
            "withinss: 17.3\n",
            "k-means trial 29,\n",
            "withinss: 17.3\n",
            "k-means trial 30,\n",
            "withinss: 17.3\n",
            "k-means trial 31,\n",
            "withinss: 17.3\n",
            "k-means trial 32,\n",
            "withinss: 17.3\n",
            "k-means trial 33,\n",
            "withinss: 17.3\n",
            "k-means trial 34,\n",
            "withinss: 17.3\n",
            "k-means trial 35,\n",
            "withinss: 17.3\n",
            "k-means trial 36,\n",
            "withinss: 17.3\n",
            "k-means trial 37,\n",
            "withinss: 17.3\n",
            "k-means trial 38,\n",
            "withinss: 17.3\n",
            "k-means trial 39,\n",
            "withinss: 17.3\n",
            "k-means trial 40,\n",
            "withinss: 17.3\n",
            "k-means trial 41,\n",
            "withinss: 17.3\n",
            "k-means trial 42,\n",
            "withinss: 17.3\n",
            "k-means trial 43,\n",
            "withinss: 17.3\n",
            "k-means trial 44,\n",
            "withinss: 17.3\n",
            "k-means trial 45,\n",
            "withinss: 17.3\n",
            "k-means trial 46,\n",
            "withinss: 17.3\n",
            "k-means trial 47,\n",
            "withinss: 17.3\n",
            "k-means trial 48,\n",
            "withinss: 17.3\n",
            "k-means trial 49,\n",
            "withinss: 17.3\n",
            "k-means trial 50,\n",
            "withinss: 17.3\n",
            "k-means trial 51,\n",
            "withinss: 17.3\n",
            "k-means trial 52,\n",
            "withinss: 17.3\n",
            "k-means trial 53,\n",
            "withinss: 17.3\n",
            "k-means trial 54,\n",
            "withinss: 17.3\n",
            "k-means trial 55,\n",
            "withinss: 17.3\n",
            "k-means trial 56,\n",
            "withinss: 17.3\n",
            "k-means trial 57,\n",
            "withinss: 17.3\n",
            "k-means trial 58,\n",
            "withinss: 17.3\n",
            "k-means trial 59,\n",
            "withinss: 17.3\n",
            "k-means trial 60,\n",
            "withinss: 17.3\n",
            "k-means trial 61,\n",
            "withinss: 17.3\n",
            "k-means trial 62,\n",
            "withinss: 17.3\n",
            "k-means trial 63,\n",
            "withinss: 17.3\n",
            "k-means trial 64,\n",
            "withinss: 17.3\n",
            "k-means trial 65,\n",
            "withinss: 17.3\n",
            "k-means trial 66,\n",
            "withinss: 17.3\n",
            "k-means trial 67,\n",
            "withinss: 17.3\n",
            "k-means trial 68,\n",
            "withinss: 17.3\n",
            "k-means trial 69,\n",
            "withinss: 17.3\n",
            "k-means trial 70,\n",
            "withinss: 17.3\n",
            "k-means trial 71,\n",
            "withinss: 17.3\n",
            "k-means trial 72,\n",
            "withinss: 17.3\n",
            "k-means trial 73,\n",
            "withinss: 17.3\n",
            "k-means trial 74,\n",
            "withinss: 17.3\n",
            "k-means trial 75,\n",
            "withinss: 17.3\n",
            "k-means trial 76,\n",
            "withinss: 17.3\n",
            "k-means trial 77,\n",
            "withinss: 17.3\n",
            "k-means trial 78,\n",
            "withinss: 17.3\n",
            "k-means trial 79,\n",
            "withinss: 17.3\n",
            "k-means trial 80,\n",
            "withinss: 17.3\n",
            "k-means trial 81,\n",
            "withinss: 17.3\n",
            "k-means trial 82,\n",
            "withinss: 17.3\n",
            "k-means trial 83,\n",
            "withinss: 17.3\n",
            "k-means trial 84,\n",
            "withinss: 17.3\n",
            "k-means trial 85,\n",
            "withinss: 17.3\n",
            "k-means trial 86,\n",
            "withinss: 17.3\n",
            "k-means trial 87,\n",
            "withinss: 17.3\n",
            "k-means trial 88,\n",
            "withinss: 17.3\n",
            "k-means trial 89,\n",
            "withinss: 17.3\n",
            "k-means trial 90,\n",
            "withinss: 17.3\n",
            "k-means trial 91,\n",
            "withinss: 17.3\n",
            "k-means trial 92,\n",
            "withinss: 17.3\n",
            "k-means trial 93,\n",
            "withinss: 17.3\n",
            "k-means trial 94,\n",
            "withinss: 17.3\n",
            "k-means trial 95,\n",
            "withinss: 17.3\n",
            "k-means trial 96,\n",
            "withinss: 17.3\n",
            "k-means trial 97,\n",
            "withinss: 17.3\n",
            "k-means trial 98,\n",
            "withinss: 17.3\n",
            "k-means trial 99,\n",
            "withinss: 17.3\n",
            "k-means trial 100,\n",
            "withinss: 17.3\n",
            "Trial with minimum withinss: 1\n",
            "centroid0\t2.50 5.00 \n",
            "centroid1\t6.83 4.00 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('X1', 3.0, 5.0), ('X2', 3.0, 4.0), ('X3', 2.0, 8.0), ('X4', 2.0, 3.0)],\n",
              " [('X5', 6.0, 2.0),\n",
              "  ('X6', 6.0, 4.0),\n",
              "  ('X7', 7.0, 3.0),\n",
              "  ('X8', 7.0, 4.0),\n",
              "  ('X9', 8.0, 5.0),\n",
              "  ('X10', 7.0, 6.0)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWr_3bio68sM"
      },
      "source": [
        "##(4) Initializing two centroids, (3, 2) and (4, 8) using Manhattan distance as the distance metric along with performing one iteration of the K-means algorithm and the reporting the coordinates of the resulting centroids.Also, Using K-Means to find two clusters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61xRiY537CBI",
        "outputId": "9829454d-8b3c-48f3-caed-08641b895ad5"
      },
      "source": [
        "centroids_4 = [('centroidA',3,2),('centroidB',4,8)]\r\n",
        "cluster_14 = kmeans(dataset, 2, initCentroids = centroids_4, distance_type = 'Manhattan')\r\n",
        "\r\n",
        "#print(\"The two clusters using k-means to find clusters: \")\r\n",
        "cluster_24 = repeatedKMeans(dataset, 2, 100,centroids_4, distance_type = 'Manhattan')\r\n",
        "printTable(cluster_14['centroids'])\r\n",
        "cluster_14[\"clusters\"]\r\n",
        "cluster_24[\"clusters\"]\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k-means trial 1,\n",
            "withinss: 29.2\n",
            "k-means trial 2,\n",
            "withinss: 29.2\n",
            "k-means trial 3,\n",
            "withinss: 29.2\n",
            "k-means trial 4,\n",
            "withinss: 29.2\n",
            "k-means trial 5,\n",
            "withinss: 29.2\n",
            "k-means trial 6,\n",
            "withinss: 29.2\n",
            "k-means trial 7,\n",
            "withinss: 29.2\n",
            "k-means trial 8,\n",
            "withinss: 29.2\n",
            "k-means trial 9,\n",
            "withinss: 29.2\n",
            "k-means trial 10,\n",
            "withinss: 29.2\n",
            "k-means trial 11,\n",
            "withinss: 29.2\n",
            "k-means trial 12,\n",
            "withinss: 29.2\n",
            "k-means trial 13,\n",
            "withinss: 29.2\n",
            "k-means trial 14,\n",
            "withinss: 29.2\n",
            "k-means trial 15,\n",
            "withinss: 29.2\n",
            "k-means trial 16,\n",
            "withinss: 29.2\n",
            "k-means trial 17,\n",
            "withinss: 29.2\n",
            "k-means trial 18,\n",
            "withinss: 29.2\n",
            "k-means trial 19,\n",
            "withinss: 29.2\n",
            "k-means trial 20,\n",
            "withinss: 29.2\n",
            "k-means trial 21,\n",
            "withinss: 29.2\n",
            "k-means trial 22,\n",
            "withinss: 29.2\n",
            "k-means trial 23,\n",
            "withinss: 29.2\n",
            "k-means trial 24,\n",
            "withinss: 29.2\n",
            "k-means trial 25,\n",
            "withinss: 29.2\n",
            "k-means trial 26,\n",
            "withinss: 29.2\n",
            "k-means trial 27,\n",
            "withinss: 29.2\n",
            "k-means trial 28,\n",
            "withinss: 29.2\n",
            "k-means trial 29,\n",
            "withinss: 29.2\n",
            "k-means trial 30,\n",
            "withinss: 29.2\n",
            "k-means trial 31,\n",
            "withinss: 29.2\n",
            "k-means trial 32,\n",
            "withinss: 29.2\n",
            "k-means trial 33,\n",
            "withinss: 29.2\n",
            "k-means trial 34,\n",
            "withinss: 29.2\n",
            "k-means trial 35,\n",
            "withinss: 29.2\n",
            "k-means trial 36,\n",
            "withinss: 29.2\n",
            "k-means trial 37,\n",
            "withinss: 29.2\n",
            "k-means trial 38,\n",
            "withinss: 29.2\n",
            "k-means trial 39,\n",
            "withinss: 29.2\n",
            "k-means trial 40,\n",
            "withinss: 29.2\n",
            "k-means trial 41,\n",
            "withinss: 29.2\n",
            "k-means trial 42,\n",
            "withinss: 29.2\n",
            "k-means trial 43,\n",
            "withinss: 29.2\n",
            "k-means trial 44,\n",
            "withinss: 29.2\n",
            "k-means trial 45,\n",
            "withinss: 29.2\n",
            "k-means trial 46,\n",
            "withinss: 29.2\n",
            "k-means trial 47,\n",
            "withinss: 29.2\n",
            "k-means trial 48,\n",
            "withinss: 29.2\n",
            "k-means trial 49,\n",
            "withinss: 29.2\n",
            "k-means trial 50,\n",
            "withinss: 29.2\n",
            "k-means trial 51,\n",
            "withinss: 29.2\n",
            "k-means trial 52,\n",
            "withinss: 29.2\n",
            "k-means trial 53,\n",
            "withinss: 29.2\n",
            "k-means trial 54,\n",
            "withinss: 29.2\n",
            "k-means trial 55,\n",
            "withinss: 29.2\n",
            "k-means trial 56,\n",
            "withinss: 29.2\n",
            "k-means trial 57,\n",
            "withinss: 29.2\n",
            "k-means trial 58,\n",
            "withinss: 29.2\n",
            "k-means trial 59,\n",
            "withinss: 29.2\n",
            "k-means trial 60,\n",
            "withinss: 29.2\n",
            "k-means trial 61,\n",
            "withinss: 29.2\n",
            "k-means trial 62,\n",
            "withinss: 29.2\n",
            "k-means trial 63,\n",
            "withinss: 29.2\n",
            "k-means trial 64,\n",
            "withinss: 29.2\n",
            "k-means trial 65,\n",
            "withinss: 29.2\n",
            "k-means trial 66,\n",
            "withinss: 29.2\n",
            "k-means trial 67,\n",
            "withinss: 29.2\n",
            "k-means trial 68,\n",
            "withinss: 29.2\n",
            "k-means trial 69,\n",
            "withinss: 29.2\n",
            "k-means trial 70,\n",
            "withinss: 29.2\n",
            "k-means trial 71,\n",
            "withinss: 29.2\n",
            "k-means trial 72,\n",
            "withinss: 29.2\n",
            "k-means trial 73,\n",
            "withinss: 29.2\n",
            "k-means trial 74,\n",
            "withinss: 29.2\n",
            "k-means trial 75,\n",
            "withinss: 29.2\n",
            "k-means trial 76,\n",
            "withinss: 29.2\n",
            "k-means trial 77,\n",
            "withinss: 29.2\n",
            "k-means trial 78,\n",
            "withinss: 29.2\n",
            "k-means trial 79,\n",
            "withinss: 29.2\n",
            "k-means trial 80,\n",
            "withinss: 29.2\n",
            "k-means trial 81,\n",
            "withinss: 29.2\n",
            "k-means trial 82,\n",
            "withinss: 29.2\n",
            "k-means trial 83,\n",
            "withinss: 29.2\n",
            "k-means trial 84,\n",
            "withinss: 29.2\n",
            "k-means trial 85,\n",
            "withinss: 29.2\n",
            "k-means trial 86,\n",
            "withinss: 29.2\n",
            "k-means trial 87,\n",
            "withinss: 29.2\n",
            "k-means trial 88,\n",
            "withinss: 29.2\n",
            "k-means trial 89,\n",
            "withinss: 29.2\n",
            "k-means trial 90,\n",
            "withinss: 29.2\n",
            "k-means trial 91,\n",
            "withinss: 29.2\n",
            "k-means trial 92,\n",
            "withinss: 29.2\n",
            "k-means trial 93,\n",
            "withinss: 29.2\n",
            "k-means trial 94,\n",
            "withinss: 29.2\n",
            "k-means trial 95,\n",
            "withinss: 29.2\n",
            "k-means trial 96,\n",
            "withinss: 29.2\n",
            "k-means trial 97,\n",
            "withinss: 29.2\n",
            "k-means trial 98,\n",
            "withinss: 29.2\n",
            "k-means trial 99,\n",
            "withinss: 29.2\n",
            "k-means trial 100,\n",
            "withinss: 29.2\n",
            "Trial with minimum withinss: 1\n",
            "centroid0\t4.86 3.57 \n",
            "centroid1\t5.67 6.33 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('X1', 3.0, 5.0),\n",
              "  ('X2', 3.0, 4.0),\n",
              "  ('X4', 2.0, 3.0),\n",
              "  ('X5', 6.0, 2.0),\n",
              "  ('X6', 6.0, 4.0),\n",
              "  ('X7', 7.0, 3.0),\n",
              "  ('X8', 7.0, 4.0)],\n",
              " [('X3', 2.0, 8.0), ('X9', 8.0, 5.0), ('X10', 7.0, 6.0)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlzPBLAXBLej"
      },
      "source": [
        "#**Task 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt5nH6isBDu_"
      },
      "source": [
        "##Q1: Run K-means clustering with Euclidean, Cosine and Jarcard similarity. Specify K= thenumber of categorical values of y (the variable of label). Compare the SSEs of Euclidean-Kmeans Cosine-K-means, Jarcard-K-means. Which method is better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrSQNzEDBeA3"
      },
      "source": [
        "from sklearn import datasets\r\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc0_JqSdNoqo",
        "outputId": "339f4fc1-7c10-43d8-cd91-2aa528396d56"
      },
      "source": [
        "iris"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
              " 'data': array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2],\n",
              "        [5.4, 3.9, 1.7, 0.4],\n",
              "        [4.6, 3.4, 1.4, 0.3],\n",
              "        [5. , 3.4, 1.5, 0.2],\n",
              "        [4.4, 2.9, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.1],\n",
              "        [5.4, 3.7, 1.5, 0.2],\n",
              "        [4.8, 3.4, 1.6, 0.2],\n",
              "        [4.8, 3. , 1.4, 0.1],\n",
              "        [4.3, 3. , 1.1, 0.1],\n",
              "        [5.8, 4. , 1.2, 0.2],\n",
              "        [5.7, 4.4, 1.5, 0.4],\n",
              "        [5.4, 3.9, 1.3, 0.4],\n",
              "        [5.1, 3.5, 1.4, 0.3],\n",
              "        [5.7, 3.8, 1.7, 0.3],\n",
              "        [5.1, 3.8, 1.5, 0.3],\n",
              "        [5.4, 3.4, 1.7, 0.2],\n",
              "        [5.1, 3.7, 1.5, 0.4],\n",
              "        [4.6, 3.6, 1. , 0.2],\n",
              "        [5.1, 3.3, 1.7, 0.5],\n",
              "        [4.8, 3.4, 1.9, 0.2],\n",
              "        [5. , 3. , 1.6, 0.2],\n",
              "        [5. , 3.4, 1.6, 0.4],\n",
              "        [5.2, 3.5, 1.5, 0.2],\n",
              "        [5.2, 3.4, 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.6, 0.2],\n",
              "        [4.8, 3.1, 1.6, 0.2],\n",
              "        [5.4, 3.4, 1.5, 0.4],\n",
              "        [5.2, 4.1, 1.5, 0.1],\n",
              "        [5.5, 4.2, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.2, 1.2, 0.2],\n",
              "        [5.5, 3.5, 1.3, 0.2],\n",
              "        [4.9, 3.6, 1.4, 0.1],\n",
              "        [4.4, 3. , 1.3, 0.2],\n",
              "        [5.1, 3.4, 1.5, 0.2],\n",
              "        [5. , 3.5, 1.3, 0.3],\n",
              "        [4.5, 2.3, 1.3, 0.3],\n",
              "        [4.4, 3.2, 1.3, 0.2],\n",
              "        [5. , 3.5, 1.6, 0.6],\n",
              "        [5.1, 3.8, 1.9, 0.4],\n",
              "        [4.8, 3. , 1.4, 0.3],\n",
              "        [5.1, 3.8, 1.6, 0.2],\n",
              "        [4.6, 3.2, 1.4, 0.2],\n",
              "        [5.3, 3.7, 1.5, 0.2],\n",
              "        [5. , 3.3, 1.4, 0.2],\n",
              "        [7. , 3.2, 4.7, 1.4],\n",
              "        [6.4, 3.2, 4.5, 1.5],\n",
              "        [6.9, 3.1, 4.9, 1.5],\n",
              "        [5.5, 2.3, 4. , 1.3],\n",
              "        [6.5, 2.8, 4.6, 1.5],\n",
              "        [5.7, 2.8, 4.5, 1.3],\n",
              "        [6.3, 3.3, 4.7, 1.6],\n",
              "        [4.9, 2.4, 3.3, 1. ],\n",
              "        [6.6, 2.9, 4.6, 1.3],\n",
              "        [5.2, 2.7, 3.9, 1.4],\n",
              "        [5. , 2. , 3.5, 1. ],\n",
              "        [5.9, 3. , 4.2, 1.5],\n",
              "        [6. , 2.2, 4. , 1. ],\n",
              "        [6.1, 2.9, 4.7, 1.4],\n",
              "        [5.6, 2.9, 3.6, 1.3],\n",
              "        [6.7, 3.1, 4.4, 1.4],\n",
              "        [5.6, 3. , 4.5, 1.5],\n",
              "        [5.8, 2.7, 4.1, 1. ],\n",
              "        [6.2, 2.2, 4.5, 1.5],\n",
              "        [5.6, 2.5, 3.9, 1.1],\n",
              "        [5.9, 3.2, 4.8, 1.8],\n",
              "        [6.1, 2.8, 4. , 1.3],\n",
              "        [6.3, 2.5, 4.9, 1.5],\n",
              "        [6.1, 2.8, 4.7, 1.2],\n",
              "        [6.4, 2.9, 4.3, 1.3],\n",
              "        [6.6, 3. , 4.4, 1.4],\n",
              "        [6.8, 2.8, 4.8, 1.4],\n",
              "        [6.7, 3. , 5. , 1.7],\n",
              "        [6. , 2.9, 4.5, 1.5],\n",
              "        [5.7, 2.6, 3.5, 1. ],\n",
              "        [5.5, 2.4, 3.8, 1.1],\n",
              "        [5.5, 2.4, 3.7, 1. ],\n",
              "        [5.8, 2.7, 3.9, 1.2],\n",
              "        [6. , 2.7, 5.1, 1.6],\n",
              "        [5.4, 3. , 4.5, 1.5],\n",
              "        [6. , 3.4, 4.5, 1.6],\n",
              "        [6.7, 3.1, 4.7, 1.5],\n",
              "        [6.3, 2.3, 4.4, 1.3],\n",
              "        [5.6, 3. , 4.1, 1.3],\n",
              "        [5.5, 2.5, 4. , 1.3],\n",
              "        [5.5, 2.6, 4.4, 1.2],\n",
              "        [6.1, 3. , 4.6, 1.4],\n",
              "        [5.8, 2.6, 4. , 1.2],\n",
              "        [5. , 2.3, 3.3, 1. ],\n",
              "        [5.6, 2.7, 4.2, 1.3],\n",
              "        [5.7, 3. , 4.2, 1.2],\n",
              "        [5.7, 2.9, 4.2, 1.3],\n",
              "        [6.2, 2.9, 4.3, 1.3],\n",
              "        [5.1, 2.5, 3. , 1.1],\n",
              "        [5.7, 2.8, 4.1, 1.3],\n",
              "        [6.3, 3.3, 6. , 2.5],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [7.1, 3. , 5.9, 2.1],\n",
              "        [6.3, 2.9, 5.6, 1.8],\n",
              "        [6.5, 3. , 5.8, 2.2],\n",
              "        [7.6, 3. , 6.6, 2.1],\n",
              "        [4.9, 2.5, 4.5, 1.7],\n",
              "        [7.3, 2.9, 6.3, 1.8],\n",
              "        [6.7, 2.5, 5.8, 1.8],\n",
              "        [7.2, 3.6, 6.1, 2.5],\n",
              "        [6.5, 3.2, 5.1, 2. ],\n",
              "        [6.4, 2.7, 5.3, 1.9],\n",
              "        [6.8, 3. , 5.5, 2.1],\n",
              "        [5.7, 2.5, 5. , 2. ],\n",
              "        [5.8, 2.8, 5.1, 2.4],\n",
              "        [6.4, 3.2, 5.3, 2.3],\n",
              "        [6.5, 3. , 5.5, 1.8],\n",
              "        [7.7, 3.8, 6.7, 2.2],\n",
              "        [7.7, 2.6, 6.9, 2.3],\n",
              "        [6. , 2.2, 5. , 1.5],\n",
              "        [6.9, 3.2, 5.7, 2.3],\n",
              "        [5.6, 2.8, 4.9, 2. ],\n",
              "        [7.7, 2.8, 6.7, 2. ],\n",
              "        [6.3, 2.7, 4.9, 1.8],\n",
              "        [6.7, 3.3, 5.7, 2.1],\n",
              "        [7.2, 3.2, 6. , 1.8],\n",
              "        [6.2, 2.8, 4.8, 1.8],\n",
              "        [6.1, 3. , 4.9, 1.8],\n",
              "        [6.4, 2.8, 5.6, 2.1],\n",
              "        [7.2, 3. , 5.8, 1.6],\n",
              "        [7.4, 2.8, 6.1, 1.9],\n",
              "        [7.9, 3.8, 6.4, 2. ],\n",
              "        [6.4, 2.8, 5.6, 2.2],\n",
              "        [6.3, 2.8, 5.1, 1.5],\n",
              "        [6.1, 2.6, 5.6, 1.4],\n",
              "        [7.7, 3. , 6.1, 2.3],\n",
              "        [6.3, 3.4, 5.6, 2.4],\n",
              "        [6.4, 3.1, 5.5, 1.8],\n",
              "        [6. , 3. , 4.8, 1.8],\n",
              "        [6.9, 3.1, 5.4, 2.1],\n",
              "        [6.7, 3.1, 5.6, 2.4],\n",
              "        [6.9, 3.1, 5.1, 2.3],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [6.8, 3.2, 5.9, 2.3],\n",
              "        [6.7, 3.3, 5.7, 2.5],\n",
              "        [6.7, 3. , 5.2, 2.3],\n",
              "        [6.3, 2.5, 5. , 1.9],\n",
              "        [6.5, 3. , 5.2, 2. ],\n",
              "        [6.2, 3.4, 5.4, 2.3],\n",
              "        [5.9, 3. , 5.1, 1.8]]),\n",
              " 'feature_names': ['sepal length (cm)',\n",
              "  'sepal width (cm)',\n",
              "  'petal length (cm)',\n",
              "  'petal width (cm)'],\n",
              " 'filename': '/usr/local/lib/python3.7/dist-packages/sklearn/datasets/data/iris.csv',\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
              " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCAh5YfR574x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GZlYNlC6PvM"
      },
      "source": [
        "##Task 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22dtiMzvXnvA"
      },
      "source": [
        "## Just testing this task 3 to check the manuall calculations\r\n",
        "\r\n",
        "from itertools import combinations\r\n",
        "import numpy as np\r\n",
        "members = [(4.7,3.2),(4.9,3.1),(5.0,3.0),(4.6,2.9),(5.9,3.2),(6.7,3.1),(6.0,3.0),(6.2,2.8)]\r\n",
        "\r\n",
        "combiningall = list(combinations(members,2))\r\n",
        "#storing\r\n",
        "distances = list()\r\n",
        "for x in combiningall:\r\n",
        "  p1 = np.array(x[0])\r\n",
        "  p2 = np.array(x[1])\r\n",
        "  euclidean_distance = round(np.linalg.norm(p1-p2),4)\r\n",
        "  distances.append(euclidean_distance)\r\n",
        "\r\n",
        "distances = np.array(distances)\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM5XBeLeaWZj"
      },
      "source": [
        "##What is the distance between the two farthest members?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QBbEhavYYzt",
        "outputId": "9dcc71fe-8f8f-44b3-a725-ed653d9f702d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "distances.max()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.1095"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS7NWbt4aaPw"
      },
      "source": [
        "## What is the distance between the two closest members?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KqRX4sAYe_b",
        "outputId": "df56eb3e-3ff5-49c4-cb97-c960ce90eb22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "distances.min()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1414"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE9f4bJIadZg"
      },
      "source": [
        "##What is the average distance between all pairs?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWMpGoHXZrhP",
        "outputId": "efa14cb4-695e-4d5e-f617-8098a602baaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "distances.mean()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9829749999999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGm13g5p6KOY"
      },
      "source": [
        "##The average distance : 0.982975\r\n"
      ]
    }
  ]
}